# finetuning-llm-course
Since making this course, better models with smaller number of parameters are released. So, we can use smaller models as mentioned, if there are any hardware constraints.

ministral/Ministral-3b-instruct instead of mistralai/Mistral-7B-v0.1
meta-llama/Llama-3.2-3B-Instruct instead of meta-llama/Llama-2-7b-hf
sarvamai/sarvam-1 instead of sarvamai/OpenHathi-7B-Hi-v0.1-Base
Qwen/Qwen2.5-Coder-7B-Instruct instead of codellama/CodeLlama-13b-Instruct-hf
